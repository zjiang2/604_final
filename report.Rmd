---
title: "Predicting County-Level COVID-19 Vaccine Hesitancy"
date: "`r format(Sys.time(), '%B %d, %Y')`"
author: "Prayag Chatha, Josh Jiang, Declan McNamara"
header-includes:
   - \usepackage{float}
output: 
  pdf_document:
    number_sections: true
    fig_crop: no
urlcolor: blue
bibliography: references.bib
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyverse)
library(gridExtra)
library(adabag)
library(ROCR)
library(viridis)
library(ggpubr)
library(ggthemes)
library(usmap)

# set chunk default
knitr::opts_chunk$set(
  echo = FALSE,  # don't print the code chunk
  warning = FALSE,  # don't print warnings
  message = FALSE,  # don't print messages
  fig.width = 6,  # set default width of figures
  fig.height = 4,  # set default height of figures
  fig.align = "center",  # always align figure in center
  fig.pos = "H")  # always plot figure at the exact location of the code
source("code/helpers.R")
# read in main data set

# set theme of ggplots (looks a lot cleaner than base config)
theme_set(theme_bw())

no_legend_theme <-theme_tufte() + 
  theme(plot.title = element_text(size = 10),
        legend.position = "none")

legend_theme <-theme_tufte() + 
  theme(plot.title = element_text(size = 10))

rotate_theme <- theme_tufte() + 
  theme(plot.title = element_text(size=16), 
        axis.text.x = element_text(angle = 90),
        legend.position = "none")

map_theme <- theme(axis.line=element_blank(), panel.grid.major=element_blank(),
                   axis.text.x=element_blank(), axis.text.y=element_blank(),
                   axis.ticks=element_blank(), axis.title.x=element_blank(),
                   axis.title.y=element_blank(), panel.grid.minor=element_blank())
```

# Introduction

As of December 2021, about 59% of the US population is fully vaccinated against COVID-19. Despite America's wealth and technologically advanced medical system (that developed the first COVID vaccine), America ranks just 19th in the world in terms of vaccination rates.^[https://ourworldindata.org/covid-vaccinations] As there is no shortage of vaccine doses domestically, lagging vaccination rates in the US are typically attributed to public hesitancy, not lack of access. Resistance to vaccination has been attributed to many sources, ranging from political polarization to consumer anxiety that the vaccine isn't actually free.

In this study, we examine the relationship between county-level vaccination rates and local demographics, such as racial makeup, economic variables, and political tendency. Counties are granular enough units of study to show interesting geographic patterns while simultaneously aggregating the behavior of individuals in particular communities, socioeconomic classes, races, and cultural groups. A quantitative study of the factors that predict vaccine adoption or resistance allows us to evaluate common media narratives about the COVID vaccine drive. Furthermore, any consistent patterns in vaccination rates can be useful in crafting public health messaging to promote vaccination efforts.

# Data
```{r loadData}
df_main <- read.csv("data/combined_county_info_0620.csv")
df_main <- clean_data(df_main)

# get list of fips with state and county
dfips <- maps::county.fips %>%
  as_tibble %>% 
  extract(polyname, c("region", "subregion"), "^([^,]+),([^,]+)$")

# append fips to map data and df_main data
dall <- map_data("county") %>% 
  left_join(dfips) %>%
  left_join(df_main, by=c("fips"="FIPS"))
```

## Data Sources
We derived our data on county-level vaccination rates^[https://github.com/covidestim/cdc-vaccine-data] from a scrape of the CDC's [county view dashboard](https://covid.cdc.gov/covid-data-tracker/#county-view) dating back to June 20th, 2021. We chose this date as roughly half of the US population had been fully vaccinated by this point in time.^[https://ourworldindata.org/covid-vaccinations?country=USA]. For potential predictors of county-level vaccination, we obtained county-level results for the 2020 US Presidential election^[https://www.kaggle.com/etsc9287/2020-general-election-polls], demographic data (e.g. racial composition, income levels) from the 2015 5-year Census estimate^[https://www.kaggle.com/muonneutrino/us-census-demographic-data], as well as county education levels (i.e. prevelance of a bachelor's degree or higher).^[https://www.ers.usda.gov/data-products/county-level-data-sets/].

## Data Overview
Our combined data set contains complete data on 2,809 counties^[Out of the approximately 3,100 counties and equivalent municipalities in the USA] in 47 states (sans Alaska, Hawaii, and Texas) as well as Washington, DC. These counties ranged from metropolitan areas^[In New York City, vaccination data for all five boroughs were combined, which led to its exclusion from the final data set.] such as Los Angeles, Cook, and Maricopa counties to rural areas containing only a few hundred inhabitants. As counties primarily represent geographic area, most counties tend to be less-populous than average.

These counties had a mean and median adult vaccination rate of 41%, with most counties falling within a range of about 30-50% vaccination. We inspected several counties with extremely high or low vaccination levels.

```{r hesitancyOverview, results="hide", fig.width=6, fig.height=3, fig.cap="Map and Distribution of 18-Plus vaccination Rates by County, June 20th, 2021"}
pp1 <- dall %>% 
  ggplot(aes(x=long, y=lat, group = group)) +
  geom_polygon(aes(fill=vax_rate_18_plus), color=NA) +
  scale_fill_gradientn(colors=c("red","orange","green","blue"), na.value="grey") +
  labs(fill = "Vax rate %") + 
  theme(text = element_text(size=5)) + map_theme

pp2 <- ggplot(df_main, aes(x=vax_rate_18_plus)) +
  geom_histogram() + xlab("% Fully Vaccinated, 18+")

grid.arrange(pp1,pp2, nrow=2, layout_matrix=matrix(c(1,1,2), nrow=1))
```

### Counties with Unusually High Vaccination Rates
The four counties with the highest vaccination rates--McKinley NM (100%), Chattahoochee GA (100%), Martin NC (86%), and Santa Cruz AZ (85%)--are all rural areas with large minority (Native American, Black, or Hispanic) populations. Several highly affluent counties, such as Montgomery MD, Marin CA, and Glacier MT had a vaccination rate of 80% or above. This suggests that counties that were particularly hard-hit by Covid-19 (i.e., poor and less-white areas) saw widespread vaccination adoption, but also that wealth correlates with vaccination. The counties with the highest vaccination rates generally leaned Democratic in the 2020 presidential election.

### Counties with Unusually Low Vaccination Rates

The counties with the lowest vaccination rates (0-2%) were mostly in rural (i.e. western) Virginia, such as Appomattox County (1.7%) and the city of Lynchburg (0.8%). Other counties at the bottom end of the range included the island of Nantucket, MA (1.2%) and Morgan County, WV (2.1%). Remarkably, the 50 counties with the lowest vaccination rate (6% or lower) are all located in either Virginia, Georgia, West Virginia, or the Cape Cod region of Massachusetts. These include both mostly-white and white-minority counties, though most of them leaned Republican in the 2020 presidential election.

### Geographic Patterns

Figure 1 shows a map of vaccination rates in the lower 48 states (minus Texas). As we saw from manual inspection, southern states West Virginia, Virginia, and Georgia are home to many counties with some of the lowest vaccination rates. The Great Plains (e.g Nebraska, North Dakota) appear to have lower-than-average vaccination adoption, though rural counties in neighboring states Minnesota and Iowa tend to be widely-inoculated. The Northeast, the West Coast, and southern Florida (notably home to many seniors) are some other areas with widespread vaccination.

## Exploratory Data Analysis

To dig further into demographic patterns of vaccine hesitancy, we figure 2 shows a scatterplot matrix for features roughly corresponding to education, ethnicity, wealth, political tendency, and population density. Blue points indicate counties with an above-average (> 41%) vaccination rate, while counties with a below-average vaccination rate are colored red. Income per capita and the percentage of adults with a college education appear to predict a high vaccination rate, while strong support for Donald Trump in the 2020 presidential election correlates negatively with vaccination. The counties with the largest populations (i.e., cities) tend to have above-average vaccination rates, though this relationship is somewhat weak. Somewhat surprisingly, a county's percentage of white population seems to be non-predictive of vaccine adoption. It seems plausible that a model based only on education, income, or the 2020 election results could do a decent job of classifying counties.

To further investigate patterns in vaccine adoption, we compared adult vaccination rates against a variety of demographic features. Figure 2 shows six of the more interesting correlation scatterplots. We see that an educated and high-earning populace tends to predict a high vaccination rate, both having a correlation coefficient of $\rho = 0.41$. In contrast, the more a county supported Donald Trump in the 2020 Presidential Election, the lower vaccination rates tend to be ($\rho = - 0.38$). We speculate that a college education would be associated with a trust of scientific and media institutions (and thus amenability to vaccination). Despite an abundance of free vaccine doses, poorer Americans may be less able to miss work for a shot or else fear hidden costs (especially if they lack health insurance). It is unsurprising that political leanings correlate so strongly with vaccination rates given that attitudes towards public health measures (e.g. mask wearing, social distancing) have been politicized since nearly the start of the pandemic.

Of the several variables pertaining to a county's racial composition, the percent of Black population had the strongest relationship with vaccination rates, showing a somewhat negative correlation ($\rho=-0.25.$). Similarly, the percentage of the workforce engaged in production (i.e., industrial or agricultural work) was a negative predictor ($\rho=-0.20.$) These suggest some disparities in either access to (or trust of) inoculation efforts. ^[Given the unfortunate history of [unethical medical experiments](https://en.wikipedia.org/wiki/Tuskegee_Syphilis_Study) run on Black Americans, racialized attitudes towards the Covid-19 vaccine is not too surprising.] We also observed that (log-scaled) population was associated with vaccination ($\rho = 0.33$), suggesting more vaccination in urban areas. More populated counties (i.e. urban Ameria) tended to vote for Joe Biden in the last election, so this effect could be merely a reflection of existing political polarization.

```{r correlations, fig.width=6, fig.height=4, fig.cap="Correlation Scatterplots for Select Demographic Features"}
plot_color <- alpha("blue", 0.6)
size = 0.4
p1 <- ggplot(data=df_main, aes(x=pct_college, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
   xlab("% College Educated") + ylab("Adult Vacc. Rate")
p2 <- ggplot(data=df_main, aes(x=IncomePerCap, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
  xlab("Income per Capita ($)") + ylab("Adult Vacc. Rate")
p3 <- ggplot(data=df_main, aes(x=percentage20_Donald_Trump, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
   xlab("% Trump Vote, 2020") + ylab("Adult Vacc. Rate")
p4 <- ggplot(data=df_main, aes(x=Black, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
  xlab("% Black") + ylab("Adult Vacc. Rate")
p5 <- ggplot(data=df_main, aes(x=Production, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
   xlab("% Prod. Workers") + ylab("Adult Vacc. Rate")
p6 <- ggplot(data=df_main %>% transform(LogPop = log(TotalPop)), aes(x=LogPop, y=vax_rate_18_plus))  + geom_point(color=plot_color, size=0.4) + 
  xlab("Log Population") + ylab("Adult Vacc. Rate")
grid.arrange(p1, p2, p3, p4, p5, p6, nrow=2, ncol=3)
```

# Classifying Low and High Vaccination Counties

```{r createTargetVariable}
pred_threshold <- 44
df_main$y <- as.integer(df_main$vax_rate_18_plus >= pred_threshold)
```

For our outcome variable, the proportion of fully-vaccinated adults, binary classification is a more tractable prediction problem than regression. Accordingly, we split counties into two categories: 1,646 low vaccination counties having a rate less than 44%, and 1,163 high vaccination counties with a rate greater than or equal to 44%. This resulted in a 59-41 split in the data. It is worth noting that about 70 million Americans live in "low" counties and 205 million Americans live in "high" counties, a further reminder that counties are better thought of as geographic units than population units.

We compare the performance of three classification models: AdaBoost, Random Forests, and Logistic Regression. We use a 75-10-15 split for training, validation, and testing sets. The purpose of the validation set is to select parameters that generalize well to unseen data with minimal overfitting, while the final performance is assessed on a previously-unseen test data set. 

## AdaBoost
AdaBoost, short for "adaptive boosting," is the classical^[Created by Freund and Schapire in 1997.] boosting algorithm for classification. Following the intuition that an ensemble of weak learners can act in concert as a strong learners, at each successive iteration AdaBoost assigns additional loss weight to previously-misclassified observations. In theory, AdaBoost learns to correct its own mistakes, and makes relatively few assumptions about the data, making it a good "out-of-the-box" classifier.

```{r adaBoost}
set.seed(1160)
select_cols <- c("y", "pct_college", "TotalPop", "Black", "Production",
                                "IncomePerCap", "Poverty", "Walk", "percentage20_Donald_Trump")
df_quant <- df_main %>% select(select_cols)
df_quant$TotalPop <- log(df_quant$TotalPop)
cci <- split_data(df_quant)
cci$train$y<- as.factor(cci$train$y)

n_trees = 1:20
L = length(n_trees)
train_aucs = rep(0, L)
val_aucs = rep(0, L)

for (i in 1:L) {
  ab_model <- boosting(y ~ ., 
                       data=cci$train, mfinal=n_trees[i])
  train_probas <- ab_model$prob[, 2]
  train_pred <- prediction(train_probas, cci$train$y)
  train_auc.tmp <- performance(train_pred, "auc")
  train_aucs[i] <- as.numeric(train_auc.tmp@y.values)
  
  val_probas <- predict.boosting(ab_model, cci$validate)$prob[, 2]
  val_pred <- prediction(val_probas, cci$validate$y)
  val_auc.tmp <- performance(val_pred, "auc")
  val_aucs[i] <- as.numeric(val_auc.tmp@y.values)
}
```

```{r adaConvergence, fig.width=5, fig.height=3, fig.cap="AdaBoost AUC Score Convergence"}
ada_conv <- data.frame(n_trees <- n_trees,
                       train_auc <- train_aucs,
                       val_auc <- val_aucs)
ggplot(data = ada_conv) + geom_line(aes(n_trees, train_auc, colour="Training")) + 
  geom_line(aes(n_trees, val_auc, colour="Validation")) +
  ylim(0.7, 1) + scale_x_continuous(name = "Number of Trees", breaks=n_trees) +
  scale_color_manual(name = "Data Set", values=c("Training" = "darkgreen", "Validation" = "orange")) +
  ylab("AUC") + labs(title="Convergence of AdaBoost Classifier")

```

We trained our AdaBoost model on the following county-level demographic features: (1) percent college educated, (2) total population, (3) percent Black, (4) percent working in production, (5) income per capita, (6) poverty rate, (7) percent of walking commuters, and (8) Trump 2020 vote share. We denote the number of trees in Adaboost, the algorithm's main parameter, as $m$, and plot the AUC scores on training and validation sets as $m$ ranges from 1 to 20. As we would expect, the model overfits the training set somewhat. As the number of trees increases past twelve, validation AUC seems to oscillate around a plateau, whereas training AUC keeps increasing. We decided to set $m=6,$ as validation AUC drops slightly at $m=7,$ and overfit starts getting significantly worse for larger $m.$ This relatively simple model achieved an average accuracy of 82.9% on the test data set as well as an AUC score of 0.90. 

The AdaBoost model depended mostly on the 2020 election results, percentage of Black population, and income per capita in that order, these features accounting for 76% of overall variable importance. The table below shows the importance percentage for each of the eight predictors.

| Feature            | % Importance |
|--------------------|--------------|
| % Black            | 23.7         |
| Income per Capita  | 16.5         |
| % College Educated | 4.9          |
| % Trump Vote       | 36.0         |
| Poverty Rate       | 6.9          |
| % Prod. Workers    | 1.3          |
| Total Population   | 6.5          |
| % Walking to Work  | 4.2          |


```{r evaluation}
set.seed(1160)
final_ab_model <- boosting(y ~., data=cci$train, mfinal=6)
test_probas <- predict.boosting(final_ab_model, cci$test)$prob[, 2]
test_pred <- prediction(test_probas, cci$test$y)
test_auc.tmp <- performance(test_pred, "auc")
test_auc <- as.numeric(test_auc.tmp@y.values)
test_acc <- mean(as.integer((test_probas >= 0.5) == cci$test$y))
```

## Random Forest

In recent years, tree-based methods have exploded in popularity due to its flexibility, ability to learn non-linear relationships, and excellent prediction accuracy. As a non-parametric classification algorithm, it makes no formal distributional assumptions about the data. Furthermore, random forests have a natural way to rank the importance of variables. The variable importance is determined by the mean difference in out-of-bag prediction error between the original data set and the data set with said variable permuted; the score is normalized by the standard deviation of the differences. We used the `randomForest` package in R to implement the algorithm.

```{r, fig.cap="Out-of-bag Error Rate for Random Forest Classifier.",fig.height=3,fig.width=5}
library(randomForest)
set.seed(12)

# get oob error rates for various number of trees
cci_rf <- split_data(df_main[,-c(2:6,8)])
tune_df <- c()

for (n in 1:20*20){
  rf_tmp <- randomForest(factor(y)~.,data=cci_rf$train[,-c(1)], ntree=n)
  oob_err <- rf_tmp$err.rate[n,1] %>% as.numeric()
  tune_df <- rbind(tune_df, c(n,oob_err))
}

tune_df <- tune_df %>% as.data.frame()
colnames(tune_df) <- c("n_trees","oob_err")

rf_pp1 <- tune_df %>%
  ggplot(aes(x=n_trees, y=oob_err)) +
  geom_point() + geom_line() +
  xlab("Number of Trees") + ylab("Out-of-bag Error")

rf_pp1
```

Similar to AdaBoost, random forest utilizes an ensemble of weak classifiers to become a strong classifier. We chose the number of trees in the forest, $B$, to be the one that minimizes out-of-bag (OOB) error. We decided to use $B=240$, although we observed that OOB error seems to bottom out after $B=100$. The algorithm was able to achieve a 85.1% prediction accuracy on the test set.

```{r, fig.cap="Feature importance for random forest classifier."}
# run rf using optimal number of trees
n <- tune_df$n_trees[which.min(tune_df$oob_err)]
rf <- randomForest(factor(y)~.,data=cci_rf$train[,-c(1)], ntree=n, importance=TRUE)

# calculate prediction accuracy of rf
rf_pred <- predict(rf, newdata=cci_rf$test[,-c(1,47)]) %>% as.numeric()
rf_acc <- pred_acc(cci_rf$test$y, rf_pred-1)

# get variable importance
var_imp <- importance(rf, type=1) %>% as.data.frame() %>%
  rownames_to_column(var="Variable") %>%
  mutate(Variable = fct_reorder(Variable, MeanDecreaseAccuracy, .desc=TRUE))

rf_pp2 <- var_imp %>% ggplot(aes(x=Variable, y=MeanDecreaseAccuracy)) +
  geom_bar(stat="identity") + 
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1, size=5))

rf_pp2
```


The random forest classifier identified four major factors using the mean decrease in prediction accuracy criteria. These four are the proportion of people who voted for Joe Biden and Donald Trump in 2020, income per capita, and proportion of people who are Black. Clearly, the source of vaccine hesitancy is multi-faceted. The four major factors show that political views and socioeconomic status play roles in mistrust of the vaccine.

## Logistic Regression

We explored whether or not a parametric model could accurately explain our data using logistic regression. This model assumes that the log odds of the probability that a given county is vaccine-hesitant can be written as a linear combination of our predictor variables, i.e.
\begin{equation}
\log \frac{P(Y = 1)}{1-P(Y=1)} = \beta_0 + \beta_1 X_1 + \cdots + \beta_p X_p.
\end{equation}

The parametric constraint may not accurately describe our data, so it will be interesting to examine how well this model performs compared to more "black-box" models like Random Forest and Adaboost, both of which make no implicit assumptions on the data generating process.

We have many degrees of freedom in the choice of which subset of predictors $(X_1, \dots, X_k)$ to use in our model. Rather than choosing a subset arbitrarily or naively (e.g., the set of all predictors), we adopt a principled approach using the forward stepwise and backward stepwise model selection process, implemented in R. The forward stepwise approach begins with the empty (intercept-only) model for the log odds, and at each steps adds in the predictor that results in the largest decrease in model AIC, terminating when no further improvement is achieved. The backward stepwise process does the same, but begins with the full model (every predictor variable) and removes a predictor at each step to increase the AIC. Additionally, we center and scale all predictors prior to the model fitting and selection process so that the coefficients $\beta_i$ will be on comparable scale.

```{r}
# Set thresholds
train_cut <- .75
valid_cut <- .10
pred_threshold <- 44

#Scale and add response; remove unneeded columns
my_dataset <- data.frame(df_main)
vaccine_hesitant <- as.factor(as.integer(my_dataset$vax_rate_18_plus >= pred_threshold))

my_dataset <- my_dataset %>%
  select(-c(state, county, FIPS, vax_rate_18_plus, vax_rate_65_plus, vax_rate_overall, y))

my_dataset <- data.frame(scale(my_dataset))
my_dataset$vaccine_hesitant = vaccine_hesitant

#Randomly shuffle rows
shuffled <- my_dataset[sample(nrow(my_dataset)),]

cut1 <- floor(nrow(shuffled)*train_cut)
cut2 <- floor(nrow(shuffled)*(train_cut + valid_cut))

train <- data.frame(shuffled[1:cut1,])
validate <- data.frame(shuffled[cut1:cut2,])
big_train <- data.frame(rbind(train, validate))
test <- data.frame(shuffled[cut2:nrow(shuffled), ])
all_of_them <- data.frame(rbind(big_train, test))
```


```{r}
# Perform forward and backward stepwise
empty_mod <- glm(vaccine_hesitant ~ 1, data=big_train, family = binomial)
full_mod <- glm(vaccine_hesitant ~ ., data=big_train, family=binomial)
fs_results_forward <- step(empty_mod, scope=list(lower=empty_mod, upper=full_mod), direction = 'forward', trace=0)
fs_results_backward <- step(full_mod, scope=list(lower=empty_mod, upper=full_mod), direction = 'backward', trace=0)
```


After running both procedures, we can examine the variables included in each model. Below, we plot the AIC of the forward stepwise model at each step, along with the predictor added at each step. We see that the final model chosen by this procedure includes 22 total predictors. 

```{r}
order <- names(fs_results_forward$R[,1])

ggplot(data=fs_results_forward$anova,
       aes(x=factor(order, levels=as.character(order)), y=AIC, group=1)) +
  geom_line() +
  xlab('Variable Added') +
  ylab('AIC') +
  ggtitle('Forward Stepwise Procedure - Logistic Regression') +
  rotate_theme
```
It's less informative to examine a similar plot for the backward stepwise procedure, as we would see the variables removed rather than those which remain. Instead, we examine the plots for the magnitude of the logistic regression coefficients for each of the two models. For the forward stepwise model, predictors are plotted in the order in which they were added to the model. For the backward stepwise model, the predictors are in arbitrary order.

```{r, fig.height=8}
mod_forward <- glm(fs_results_forward$formula, data=big_train, family=binomial)
mod_backward <- glm(fs_results_backward$formula, data=big_train, family=binomial)

df_f <- data.frame(cbind(names(mod_forward$coefficients), as.double(mod_forward$coefficients)), as.factor(sign(mod_forward$coefficients)))[-1,] %>%
  rename(Variable = X1,
         Coefficient = X2,
         Sign = 3) %>%
  mutate(Variable = factor(Variable, levels=as.character(Variable)),
         Coefficient = as.double(Coefficient),
         Sign = as.character(Sign))

forward_plot <- ggplot(df_f, aes(x=Variable, y=Coefficient)) +
  geom_bar(aes(fill=Sign), stat = 'identity') +
  scale_fill_viridis(discrete = T) + 
  rotate_theme
  #scale_fill_manual(values=c('red', 'blue')) +

df_b <- data.frame(cbind(names(mod_backward$coefficients), as.double(mod_backward$coefficients)), as.factor(sign(mod_backward$coefficients)))[-1,] %>%
  rename(Variable = X1,
         Coefficient = X2,
         Sign = 3) %>%
  mutate(Variable = factor(Variable, levels=as.character(Variable)),
         Coefficient = as.double(Coefficient),
         Sign = as.character(Sign))

backward_plot <- ggplot(df_b, aes(x=Variable, y=Coefficient)) +
  geom_bar(aes(fill=Sign), stat = 'identity') +
  scale_fill_viridis(discrete = T) + 
  rotate_theme
  #scale_fill_manual(values=c('red', 'blue')) +

ggarrange(forward_plot, backward_plot,
          nrow=2,
          ncol=1)
```
Because the data are standardized, the scale of the coefficients are comparable, allowing us to use these coefficients as surrogates for variable importance in the prediction problem. Larger coefficients in magnitude indicate a feature which a higher impact on the log odds of a county being vaccine hesitant - large positive coefficients indicate that a county with higher values for a particular predictor are *more* likely to be vaccine hesitant; large negative coefficients indicate that large values for that predictor are likely to indicate a county that is not vaccine hesitant.

Keep this interpretation in mind, the results are somewhat surprising, particularly politically. Naively, one might expect counties with larger share of democratic voters (higher values for \texttt{percentage20_Joe_Biden}) to be less vaccine hesitant, yet rather surprisingly our data suggests the opposite. A large positive coefficient on this \texttt{percentage20_Joe_Biden} indicates that a county with a higher than usual value for this field is more likely to be vaccine hesitant. Of course, interpretation is not so simple: we also see a positive coefficient on \texttt{percentage20_Donald_Trump} which runs counter to the intuition that the coefficients on these two predictors should be different signs. Part of the difficultly in interpreting these numbers is that the coefficients should be considered as the impact of the predictor \textit{after controlling for the effects of the others}. As some of the predictors are highly correlated with one another, this intricacy may make interpretation more difficult.

That being said, many of the results are still intuitive. We see in both models a negative coefficient on the percentage of people who are college educated, suggesting that education makes people in general less vaccine-hesitant. Counties which have in general been hit harder (either overall, or presently) with COVID-19 seem to be less vaccine-hesitant as well, as indicated by the negative coefficients on \texttt{cases_avg, cases_avg_per_100k, deaths_avg} in both models.

Characterizing the other predictors is somewhat difficult, but in general we speculate that many can regarded with respect to how urban a particular county is. Increased rates of office work, per capita income, poverty, and commute time all seem to suggest a county is less likely to be vaccine-hesitant, and intuitively we tend to associate these attributes with more urban living. Some attributes associated with more rural living (e.g., a lack of racial diversity in the form of a high percentage of "White" residents) on the other hand tend to suggest increased vaccine hesitancy. 


## Comparison of models / assessment of errors


# Post-Hoc Analysis

Since random forest is the best classification model considered, we will perform some post-hoc analysis on its performance. In particular, we will perform an analysis on the classification error of the algorithm to identify where it face problems. We decided to use the entire data set in this analysis. For a given observation $x_i$ in the training set, we predicted it using only trees not trained on the observation. Of course, while the results of the training set will not reflect the true capabilities of the random forest, we believe it will be close enough. Meanwhile, we gain more data into classification error of the algorithm.

\begin{table}[htp]
\centering
\caption{Confusion matrix for random forest. FP=0.190, FN=0.173.}
\begin{tabular}{|l|l|l|}
\hline
& Vaccine Willing & Vaccine Hesitant \\ \hline
Positive & 861 & 202\\ \hline
Negative & 302 & 1444\\ \hline
\end{tabular}
\end{table}

```{r, fig.cap="Map of counties color coded by classification result using random forest."}
# get rf predictions
train_pred <- predict(rf) %>% as.numeric()
test_pred <- predict(rf, newdata=cci_rf$test[,-c(1,47)]) %>% as.numeric()
valid_pred <- predict(rf, newdata=cci_rf$validate[,-c(1,47)]) %>% as.numeric()

# combine predictions, actual, FIPS
res <- cbind(c(cci_rf$train$FIPS, cci_rf$test$FIPS, cci_rf$valid$FIPS),
             c(cci_rf$train$y, cci_rf$test$y, cci_rf$valid$y),
             c(train_pred, test_pred, valid_pred)-1) %>% as.data.frame()
colnames(res) <- c("FIPS","actual","pred")

# plot
ph1 <- dall %>%
  left_join(res, by=c("fips"="FIPS")) %>%
  mutate(result = ifelse(is.na(actual), "NA", 
                  ifelse(actual==1 & pred==1, "true positive",
                  ifelse(actual==0 & pred==0, "true negative",
                  ifelse(actual==1 & pred==0, "false negative",
                         "false positive"))))) %>% 
  ggplot(aes(x=long, y=lat, group = group)) +
  geom_polygon(aes(fill=result), color=NA) +
  scale_fill_manual(values=c("NA"="grey", "true positive"="blue",
                             "true negative"="darkgreen", "false positive"="purple",
                             "false negative"="red")) +
  map_theme

ph1
```

In the map of classification results, we see the counties that were correctly and incorrectly classified and in what way. There appears to be a concentration of misclassifications at the border of hesitancy regions. For example we see a concentration of misclassifcations in parts of Illinois, Indiana, Ohio, Kentucky. Those states are known to be the boundary between the midwest/northeast, which are largely vaccine willing regions, and the south, which is largely vaccine hesitant.

# Stability Check

```{r altDataSet}
df_april <- read.csv("data/combined_county_info_0418.csv")
df_april <- clean_data(df_april, drop=FALSE)
# compare 
```


# Conclusion

# Bibliography





